{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action Recognition Model\n",
    "====================\n",
    "\n",
    ">###### The model is a simple 3-layer DNN.\n",
    ">\n",
    ">###### It takes several sets of human key points as input, \n",
    ">\n",
    ">###### and output which action are the human doing.\n",
    "\n",
    "## Data Structure\n",
    "\n",
    "* ### Body_Parts\n",
    "* ### 1 x 95 array as input \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1267\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d9badcdc40d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mtrain_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-d9badcdc40d7>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mbatch_x\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mbatch_y\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from data_loader import load_training_and_testing_data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "train_x, train_y, test_x, test_y = load_training_and_testing_data()\n",
    "\n",
    "n1_nodes = 700\n",
    "n2_nodes = 600\n",
    "n3_nodes = 500\n",
    "\n",
    "n_classes = 9\n",
    "batch_size = 100\n",
    "\n",
    "x = tf.placeholder('float', [None, len(train_x[0])])\n",
    "y = tf.placeholder('float', [None, len(train_y[0])])\n",
    "\n",
    "def neural_network_3layer_model(data):\n",
    "    \n",
    "    hidden_layer1 = {\"weights\":tf.Variable(tf.random_normal([len(train_x[0]), n1_nodes])), \n",
    "                     \"bias\":tf.Variable(tf.random_normal([n1_nodes]))}\n",
    "    \n",
    "    hidden_layer2 = {\"weights\":tf.Variable(tf.random_normal([n1_nodes, n2_nodes])), \n",
    "                     \"bias\":tf.Variable(tf.random_normal([n2_nodes]))}\n",
    "    \n",
    "    hidden_layer3 = {\"weights\":tf.Variable(tf.random_normal([n2_nodes, n3_nodes])), \n",
    "                     \"bias\":tf.Variable(tf.random_normal([n3_nodes]))}\n",
    "    \n",
    "    output_layer = {\"weights\":tf.Variable(tf.random_normal([n3_nodes, n_classes])), \n",
    "                     \"bias\":tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(data, hidden_layer1[\"weights\"]), hidden_layer1[\"bias\"])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "    \n",
    "    l2 = tf.add(tf.matmul(l1, hidden_layer2[\"weights\"]), hidden_layer2[\"bias\"])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    \n",
    "    l3 = tf.add(tf.matmul(l2, hidden_layer3[\"weights\"]), hidden_layer3[\"bias\"])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "    \n",
    "    output = tf.add(tf.matmul(l3, output_layer[\"weights\"]), output_layer[\"bias\"])\n",
    "    \n",
    "    return output\n",
    "\n",
    "def fully_connected_model(data):\n",
    "    output_layer = {\"weights\":tf.Variable(tf.random_normal([784, n_classes])), \n",
    "                     \"bias\":tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    output = tf.add(tf.matmul(data, output_layer[\"weights\"]), output_layer[\"bias\"])\n",
    "    \n",
    "    return output\n",
    "\n",
    "def train_neural_network(x):\n",
    "    prediction = neural_network_3layer_model(x)\n",
    "    #prediction = fully_connected_model(x)\n",
    "    #forwar\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
    "    #backward propogation\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    num_of_epoches = 10\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, \"float\"))\n",
    "        \n",
    "        for epoch in range(num_of_epoches):\n",
    "            epoch_loss = 0\n",
    "            \n",
    "            i = 0\n",
    "            while i < len(train_x):\n",
    "                start = i\n",
    "                end = i + batch_size\n",
    "                batch_x  = np.array(train_x[start:end])\n",
    "                batch_y  = np.array(train_y[start:end])\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y:batch_y})\n",
    "                epoch_loss += c\n",
    "                i+=batch_size\n",
    "            print(\"Epoch \", epoch+1, \" completed out of \", num_of_epoches, \" loss \", epoch_loss)\n",
    "            print(\"Training Accuracy: \", accuracy.eval({x:test_x, y:test_y}))\n",
    "            \n",
    "        print(\"Testing Accuracy: \", accuracy.eval({x:test_x, y:test_y}))\n",
    "        \n",
    "train_neural_network(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1267\n"
     ]
    }
   ],
   "source": [
    "from data_loader import load_training_and_testing_data\n",
    "train_x, train_y, test_x, test_y = load_training_and_testing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "756\n",
      "756\n",
      "720\n",
      "756\n",
      "756\n",
      "756\n",
      "720\n",
      "756\n",
      "720\n",
      "720\n",
      "756\n",
      "720\n",
      "720\n",
      "756\n",
      "756\n",
      "720\n",
      "756\n",
      "756\n",
      "720\n",
      "720\n",
      "720\n",
      "756\n",
      "720\n",
      "756\n",
      "756\n",
      "756\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "756\n",
      "720\n",
      "756\n",
      "720\n",
      "756\n",
      "720\n",
      "720\n",
      "720\n",
      "756\n",
      "720\n",
      "720\n",
      "720\n",
      "756\n",
      "720\n",
      "756\n",
      "756\n",
      "720\n",
      "720\n",
      "720\n",
      "756\n",
      "720\n",
      "756\n",
      "720\n",
      "756\n",
      "756\n",
      "720\n",
      "720\n",
      "756\n",
      "720\n",
      "720\n",
      "756\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "756\n",
      "720\n",
      "756\n",
      "756\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "720\n",
      "756\n",
      "720\n",
      "720\n",
      "720\n",
      "756\n",
      "756\n",
      "720\n",
      "720\n",
      "720\n"
     ]
    }
   ],
   "source": [
    "a = np.array(train_x[1:100])\n",
    "k = np.array(train_y[1:100])\n",
    "for i in range(100):\n",
    "    print(len(train_x[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
